{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bluedata-Consulting/GAAPB02-training/blob/main/SLEFLEARNING_Prompt_Engineering_with_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZBMUH466r3l"
      },
      "source": [
        "# Prompt Engineering Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttnQfHTkZJbC"
      },
      "source": [
        "\n",
        "\n",
        "This guide provides an introduction to prompt engineering techniques for Azure OpenAI services, focusing on how to craft effective prompts to elicit desired responses from large language models (LLMs).\n",
        "\n",
        "### Core Concepts\n",
        "\n",
        "**What is Prompt Engineering?**\n",
        "\n",
        "Prompt engineering is the art and science of designing effective prompts to guide LLMs toward generating the desired output. It's about understanding how LLMs process information and using that knowledge to create prompts that are clear, specific, and unambiguous.\n",
        "\n",
        "**Why is Prompt Engineering Important?**\n",
        "\n",
        "* **Accuracy:** Well-crafted prompts significantly improve the accuracy and relevance of the generated responses.\n",
        "* **Control:**  Prompt engineering gives you control over the style, format, and content of the output.\n",
        "* **Efficiency:** Effective prompts can minimize the number of iterations needed to achieve the desired results, saving time and resources.\n",
        "* **Customization:** Prompt engineering allows you to tailor the LLM's behavior to specific tasks and domains.\n",
        "\n",
        "\n",
        "### Key Techniques and Examples\n",
        "\n",
        "\n",
        "**1.  Clear and Specific Instructions:**\n",
        "\n",
        "* **Bad Prompt:**  \"Tell me about dogs.\"  (Too vague, could result in a wide range of responses.)\n",
        "* **Good Prompt:** \"Write a 200-word essay comparing and contrasting the characteristics of Golden Retrievers and German Shepherds.\" (Specific, sets length and topic.)\n",
        "\n",
        "\n",
        "**2.  Few-Shot Learning:**\n",
        "\n",
        "Provide examples of input-output pairs to guide the model.\n",
        "\n",
        "* **Example:**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEQ12KDFZIoh"
      },
      "source": [
        "Make Sure, Below Environment Variables are created already:\n",
        "\n",
        "\n",
        "```\n",
        "AZURE_OPENAI_API_KEY\n",
        "AZURE_OPENAI_ENDPOINT\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d03XRAu_XflY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ['AZURE_OPENAI_ENDPOINT'] = \"\"\n",
        "#os.environ['AZURE_OPENAI_API_KEY'] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HVEaMctAXC6D"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "client = AzureOpenAI(api_version=\"2024-12-01-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0WAxkVWZ7LRi"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(prompt,model=\"myllm\",temperature=0):\n",
        "  messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature=temperature\n",
        "  )\n",
        "  return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1xrQNg0br00"
      },
      "source": [
        "## Zero Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DpqkFzDvsTe",
        "outputId": "d09df8e0-d7da-4c6d-e217-f1f5fd3bb56d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Title: The Magic of Memories**\n",
            "\n",
            "**Setting:** A cozy living room filled with family photos, a warm fireplace, and the smell of freshly baked cookies.\n",
            "\n",
            "**Characters:**\n",
            "- **Lily:** A curious 8-year-old girl.\n",
            "- **Grandpa Joe:** A wise and gentle grandfather with a twinkle in his eye.\n",
            "\n",
            "---\n",
            "\n",
            "**Lily:** (snuggling into the big armchair) Grandpa, can you tell me a story? A real one, about when you were a kid?\n",
            "\n",
            "**Grandpa Joe:** (chuckling) Oh, I have plenty of those! Let me think… Ah! How about the time I built a treehouse with my friends?\n",
            "\n",
            "**Lily:** A treehouse? That sounds amazing! How did you do it?\n",
            "\n",
            "**Grandpa Joe:** Well, we didn’t have fancy tools like you do today. We used old wooden planks we found and some rusty nails. We climbed up into the big oak tree in my backyard. It felt like we were building a castle in the sky!\n",
            "\n",
            "**Lily:** (eyes wide) Did you have a secret password to get in?\n",
            "\n",
            "**Grandpa Joe:** (grinning) Of course! We decided that only the bravest adventurers could enter. Our password was “Dragonfly.” If you didn’t say it right, you had to do a silly dance!\n",
            "\n",
            "**Lily:** (giggling) I would love to see that! Did you have any adventures in your treehouse?\n",
            "\n",
            "**Grandpa Joe:** Oh, many! One time, we pretended we were pirates searching for buried treasure. We made a map and everything! But instead of gold, we found my mom’s old jewelry box filled with costume jewelry. We thought we were rich!\n",
            "\n",
            "**Lily:** (leaning forward) What did you do with the jewelry?\n",
            "\n",
            "**Grandpa Joe:** We wore it like kings and queens! We even had a tea party up there, with cookies and lemonade. It was the best day ever.\n",
            "\n",
            "**Lily:** (sighing) That sounds so fun! I wish I could have a treehouse like that.\n",
            "\n",
            "**Grandpa Joe:** (smiling) You know, you can still have adventures, even without a treehouse. You just need a little imagination. \n",
            "\n",
            "**Lily:** (thoughtfully) Like when I pretend my blanket is a magic carpet?\n",
            "\n",
            "**Grandpa Joe:** Exactly! And remember, every time you create a story or a game, you’re building your own kind of magic.\n",
            "\n",
            "**Lily:** (brightening) Can we build a fort together? We can use blankets and pillows!\n",
            "\n",
            "**Grandpa Joe:** (nodding enthusiastically) That sounds like a wonderful idea! We can make it our secret hideout. \n",
            "\n",
            "**Lily:** (jumping up) Yay! And we can have a secret password too!\n",
            "\n",
            "**Grandpa Joe:** (laughing) Yes! How about “Cookie Monster”? \n",
            "\n",
            "**Lily:** (giggling) Perfect! Let’s go!\n",
            "\n",
            "(They rush off to gather blankets and pillows, laughter echoing through the house, as the warmth of their shared memories fills the air.)\n",
            "\n",
            "---\n",
            "\n",
            "**The End**\n"
          ]
        }
      ],
      "source": [
        "# zero shot prompting\n",
        "prompt = f\"\"\"\n",
        "Create a conversation story between child and grandparent.\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcBE11_6vwJd"
      },
      "source": [
        "## Few Shot Prompting\n",
        "\n",
        "Here, the model is given a few examples (shots) to guide its response. By providing context or previous instances, the model can better understand and generate the desired output. For example, showing a model several examples of translated sentences before asking it to translate a new one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SurLNqfa6wi",
        "outputId": "6b5f377b-bb15-439d-d2bd-fc93fb8e7839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<grandma>: Resilience is like a tree that bends in the wind but doesn’t break. It stands tall again after the storm passes, ready to grow even stronger.\n"
          ]
        }
      ],
      "source": [
        "# few shot prompting\n",
        "prompt = f\"\"\"\n",
        "your task is to answer in a consistent sytle:\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "<grandma>: Patience is like waiting for whole day to see the moon in the evening and then sleeping after having a look at it.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqtJ2ipJbhw6"
      },
      "source": [
        "#### Few shot prompting with role setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTawSemLbhw6",
        "outputId": "981db93b-1871-4f8b-ea6a-521eb5618b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "result = client.chat.completions.create(\n",
        "    model='myllm',  # e.g. gpt-35-instant\n",
        "    max_tokens=200,\n",
        "    temperature=0.9,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"That was an awesome experience\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"positive\"},\n",
        "        {\"role\": \"user\", \"content\": \"I won't do that again\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"negative\"},\n",
        "        {\"role\": \"user\", \"content\": \"That was not worth my time\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"negative\"},\n",
        "        {\"role\": \"user\", \"content\": \"You can't miss this\"}\n",
        "    ],\n",
        ")\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IBIItcqbhw_"
      },
      "source": [
        "## Chain of Thought Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbMnOeiq2atC",
        "outputId": "62b08ac7-995d-469f-e8a6-96789308d044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To find out how many pens Marry has now, we can break it down step by step:\n",
            "\n",
            "1. Marry started with 5 pens.\n",
            "2. She gave away 3 pens, so now she has:  \n",
            "   \\( 5 - 3 = 2 \\) pens.\n",
            "3. She then bought 2 boxes of pens, with 3 pens in each box. So, the total number of pens she bought is:  \n",
            "   \\( 2 \\times 3 = 6 \\) pens.\n",
            "4. Now, we add the pens she has left to the pens she bought:  \n",
            "   \\( 2 + 6 = 8 \\) pens.\n",
            "\n",
            "So, Marry has 8 pens now.\n"
          ]
        }
      ],
      "source": [
        "# Without Chain of Thought Prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Teacher: Johan had 5 apples, he bought 4 more boxes with 5 apples each. How many apples does he have now?\n",
        "Student: 25 apples\n",
        "\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Hz_cvLbhw_",
        "outputId": "2235d9bc-1809-4a39-c860-9fa7c207d89b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marry had 5 pens, she gave away 3 pens, so she has:\n",
            "\n",
            "5 - 3 = 2 pens left.\n",
            "\n",
            "Then, she bought 2 boxes of pens with 3 pens in each box, which means she bought:\n",
            "\n",
            "2 * 3 = 6 pens.\n",
            "\n",
            "Now, we add the pens she has left to the pens she bought:\n",
            "\n",
            "2 + 6 = 8 pens.\n",
            "\n",
            "So, Marry has 8 pens now.\n"
          ]
        }
      ],
      "source": [
        "# with Chain of Thought prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Teacher: Johan had 5 apples, he bought 4 more boxes with 5 apples each. How many apples does he have now?\n",
        "Student: Johan had 5 apples, 4 boxes with 5 apples each = 5 + 4*5 = 25 apples\n",
        "\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7SWadXtr5ou",
        "outputId": "a7e4bda4-38e6-4fcb-81d7-bcf568a6579f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's break down the problem step by step:\n",
            "\n",
            "1. **Initial Number of Pens**: Marry starts with 5 pens.\n",
            "\n",
            "2. **Pens Given Away**: She gives 3 pens to her friend. \n",
            "   - To find out how many pens she has left after giving away the pens, we subtract the number of pens given away from the initial number:\n",
            "   \\[\n",
            "   5 - 3 = 2 \\text{ pens}\n",
            "   \\]\n",
            "\n",
            "3. **Buying New Pens**: Marry then buys 2 boxes of pens, with each box containing 3 pens.\n",
            "   - First, we calculate the total number of pens in the boxes:\n",
            "   \\[\n",
            "   2 \\text{ boxes} \\times 3 \\text{ pens per box} = 6 \\text{ pens}\n",
            "   \\]\n",
            "\n",
            "4. **Total Number of Pens Now**: To find out how many pens Marry has now, we add the pens she has left after giving some away to the new pens she bought:\n",
            "   \\[\n",
            "   2 \\text{ pens} + 6 \\text{ pens} = 8 \\text{ pens}\n",
            "   \\]\n",
            "\n",
            "So, after following all the steps, Marry has **8 pens** now.\n"
          ]
        }
      ],
      "source": [
        "# with Chain of Thought prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Think step by step to answer below question, do not come to conclusion without following process.\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQvoNRxqVo5_"
      },
      "source": [
        "## Tree of Thoughts (ToT)\n",
        "\n",
        "Tree of Thoughts (ToT) prompting is a framework that generalizes over chain-of-thought prompting and encourages exploration over thoughts that serve as intermediate steps for general problem-solving with language models.\n",
        "\n",
        "\n",
        "How does it work?\n",
        "\n",
        "- ToT prompting breaks problems down into smaller parts, similar to CoT prompting, but goes further by combining this with the ability to explore multiple solution paths in parallel, forming a tree instead of a single chain. Each thought is generated or solved independently and passed to the next step, allowing the model to self-evaluate and decide whether to continue with that path or choose another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF7_WBM9MT78",
        "outputId": "bfb30f22-0959-4552-c990-981113febb12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Expert 1: The Physical Movement Expert\n",
            "**Step 1:** Carlos starts at the swimming pool and walks to the locker room carrying a towel. The first thing to consider is that he puts his watch in the towel before heading to the lounger. This means the watch is initially in the towel when he leaves the locker room. \n",
            "\n",
            "**Critique:** This step is solid as it establishes the initial condition of the watch being in the towel. However, I need to consider what happens to the towel after he shakes it at the lounger.\n",
            "\n",
            "**Likelihood of correctness:** 90%\n",
            "\n",
            "---\n",
            "\n",
            "### Expert 2: The Towel Dynamics Expert\n",
            "**Step 2:** After Carlos puts his watch in the towel and shakes it at the lounger, there is a possibility that the watch could fall out during the vigorous shaking. The towel is not a sealed container, so the watch could easily slip out if it was not held tightly.\n",
            "\n",
            "**Critique:** This is a valid point. The action of shaking the towel introduces a risk of the watch falling out. However, we need to consider where the towel is left after this action.\n",
            "\n",
            "**Likelihood of correctness:** 85%\n",
            "\n",
            "---\n",
            "\n",
            "### Expert 3: The Snack Bar Expert\n",
            "**Step 3:** Carlos leaves the towel at the snack bar after he shakes it at the lounger. If the watch fell out during the shaking, it could be on the ground at the lounger or still in the towel when he leaves it at the snack bar. We need to assess the likelihood of the watch being left at the lounger versus being in the towel at the snack bar.\n",
            "\n",
            "**Critique:** This step is crucial as it narrows down the potential locations. However, we need to consider the environment of both the lounger and the snack bar. \n",
            "\n",
            "**Likelihood of correctness:** 80%\n",
            "\n",
            "---\n",
            "\n",
            "### Expert 4: The Environmental Context Expert\n",
            "**Step 4:** The lounger area is likely to be more crowded and less controlled than the snack bar area. If the watch fell out at the lounger, it could easily be picked up by someone else. In contrast, if the watch remained in the towel at the snack bar, it would be more likely to be noticed by Carlos when he returns. \n",
            "\n",
            "**Critique:** This is a good observation about the environment. However, we should also consider how long Carlos was away from the towel and whether he would have noticed the watch missing if it was still in the towel.\n",
            "\n",
            "**Likelihood of correctness:** 75%\n",
            "\n",
            "---\n",
            "\n",
            "### Expert 5: The Time Factor Expert\n",
            "**Step 5:** Carlos walks to the diving board after leaving the towel at the snack bar. If he was away from the towel for a significant amount of time, he might not have noticed the watch missing if it fell out at the lounger. The longer he is away, the less likely he is to remember where he last had the watch. \n",
            "\n",
            "**Critique:** This is an important factor. The time elapsed could affect his memory of the watch's location. However, we still need to determine the most likely scenario based on the previous steps.\n",
            "\n",
            "**Likelihood of correctness:** 70%\n",
            "\n",
            "---\n",
            "\n",
            "### Group Discussion and Conclusion\n",
            "After discussing each step, the experts agree that the most likely scenario is that the watch fell out of the towel while Carlos was shaking it at the lounger. The likelihood of it being left in the towel at the snack bar is lower due to the potential for it to be noticed and picked up.\n",
            "\n",
            "**Final Agreement:** The single most likely location of the watch is at the lounger, where it may have fallen out during the vigorous shaking. \n",
            "\n",
            "**Final Likelihood of correctness:** 85%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = \"\"\"\n",
        "Imagine 5 different experts are answering this question.\n",
        "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "They will each critique their response, and the all the responses of others\n",
        "They will check their answer based on science and the laws of physics\n",
        "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
        "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
        "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
        "Each expert will assign a likelihood of their current assertion being correct\n",
        "Continue until the experts agree on the single most likely location\n",
        "The question is.\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPnsQc3hpQ7x"
      },
      "source": [
        "## Chain-of-Verification Prompting\n",
        "\n",
        "The Chain-of-Verification (CoVe) prompt engineering method aims to reduce hallucinations through a verification loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9mjZtAJfDdm",
        "outputId": "66804ced-2bb2-4a20-d2ba-9c2b3ae40cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Initial Response:**\n",
            "Some athletes who were born in the United States include:\n",
            "1. Michael Jordan (Basketball)\n",
            "2. Serena Williams (Tennis)\n",
            "3. Tom Brady (American Football)\n",
            "4. Simone Biles (Gymnastics)\n",
            "5. LeBron James (Basketball)\n",
            "\n",
            "**Verification Questions:**\n",
            "1. **What sport is Michael Jordan known for?**\n",
            "   - Answer: Basketball\n",
            "   - Verification: Michael Jordan is widely recognized as one of the greatest basketball players of all time, having played primarily for the Chicago Bulls in the NBA.\n",
            "\n",
            "2. **Is Serena Williams a professional athlete? If so, in what sport?**\n",
            "   - Answer: Yes, she is a professional athlete in tennis.\n",
            "   - Verification: Serena Williams is a highly successful tennis player, known for her numerous Grand Slam titles and contributions to the sport.\n",
            "\n",
            "3. **What position does Tom Brady play in American Football?**\n",
            "   - Answer: Quarterback\n",
            "   - Verification: Tom Brady is known for his role as a quarterback, having played for the New England Patriots and the Tampa Bay Buccaneers.\n",
            "\n",
            "4. **What is Simone Biles famous for?**\n",
            "   - Answer: Gymnastics\n",
            "   - Verification: Simone Biles is a celebrated gymnast, known for her exceptional performances and multiple Olympic medals.\n",
            "\n",
            "5. **What team does LeBron James play for?**\n",
            "   - Answer: As of October 2023, LeBron James plays for the Los Angeles Lakers.\n",
            "   - Verification: LeBron James is currently a player for the Los Angeles Lakers in the NBA, having had a storied career with multiple teams.\n",
            "\n",
            "**Final Verified Response:**\n",
            "Some athletes who were born in the United States include:\n",
            "1. Michael Jordan (Basketball)\n",
            "2. Serena Williams (Tennis)\n",
            "3. Tom Brady (American Football)\n",
            "4. Simone Biles (Gymnastics)\n",
            "5. LeBron James (Basketball, currently with the Los Angeles Lakers) \n",
            "\n",
            "This final response has been verified for accuracy based on the verification questions and their answers.\n"
          ]
        }
      ],
      "source": [
        "Question=\"Name some athletes who were born in United states\"\n",
        "\n",
        "prompt=f'''Here is the question: {Question}.\n",
        "\n",
        "First, generate a response.\n",
        "\n",
        "Then, create and answer verification questions based on this response to check for accuracy. Think it through and make sure you are extremely accurate based on the question asked.\n",
        "\n",
        "After answering each verification question, consider these answers and revise the initial response to formulate a final, verified answer. Ensure the final response reflects the accuracy and findings from the verification process.'''\n",
        "\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8_TNNG2Ozu6"
      },
      "source": [
        "# Model Limitations: Hallucinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6cFKxLnw5U7",
        "outputId": "96bf241e-2d86-41bf-b1ca-b286bb7e4f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Gather warm water and mix it with some detergent.  \n",
            "Step 2: Place the dirty clothes into the mixture and let them soak for a while.  \n",
            "Step 3: Allow the stains to loosen and mix with the water during the soaking period.  \n",
            "Step 4: Remove the clothes from the water and use a soft brush to rub off any remaining dirt or stains.  \n",
            "Step 5: Rinse the clothes in clean water to remove the detergent.  \n",
            "Step 6: Hang the clothes on a rope to dry.  \n",
            "Step 7: Enjoy your clean clothes!\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "Washing clothes without washing machines is easy!\n",
        "First you need to get some warm water. Mix the warm water with some detergent. Second you can put the dirty clothes in it and let it stay wet for some time.\n",
        "During this period the stains will get loose and mixed with water.\n",
        "thereafter you can take clothes out, rub the dirt/stains with a soft brush to remove the stains if any.\n",
        "get the clothes mixed with water to get the detergent out of it. and then put it for drying on a rope.\n",
        "Enjoy the clean clothes.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks. Rewrite those into a set of instructions in the following format:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIQvR5L9w5U8",
        "outputId": "a3f71bb6-88c5-4321-9736-8a8476958bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Observe the morning weather and take note of the brightness of the sun.  \n",
            "Step 2: Look for clouds in the sky and appreciate the contrast with the sunlight.  \n",
            "Step 3: Enjoy the pleasant weather and take a moment to feel the wind.  \n",
            "Step 4: Reflect on your overall feelings about the day and embrace the positivity.\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "THe morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing. on a whole i am loving the day today.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks. Rewrite those into a set of instructions in the following format:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVg4XE5dw5U8",
        "outputId": "d5db6ed5-c976-447a-f02b-753477924f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Get some warm water.  \n",
            "Step 2: Mix the warm water with some detergent.  \n",
            "Step 3: Put the dirty clothes in the mixture and let them stay wet for some time.  \n",
            "Step 4: Take the clothes out and rub the dirt/stains with a soft brush to remove any stains.  \n",
            "Step 5: Rinse the clothes with water to get the detergent out.  \n",
            "Step 6: Hang the clothes on a rope for drying.  \n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "Washing clothes without washing machines is easy!\n",
        "First you need to get some warm water. Mix the warm water with some detergent. Second you can put the dirty clothes in it and let it stay wet for some time.\n",
        "During this period the stains will get loose and mixed with water.\n",
        "thereafter you can take clothes out, rub the dirt/stains with a soft brush to remove the stains if any.\n",
        "get the clothes mixed with water to get the detergent out of it. and then put it for drying on a rope.\n",
        "Enjoy the clean clothes.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks.\n",
        "Rewrite those into a set of instructions in the following format only if contains a sequence of instructions:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\n",
        "if the text does not contain a sequence of instructions, then simply write 'No steps provided'\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTNZlh8kw5U9",
        "outputId": "48744b8e-14bd-48f5-efde-b86c218676b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No steps provided\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "THe morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing. on a whole i am loving the day today.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks.\n",
        "Rewrite those into a set of instructions in the following format only if contains a sequence of instructions:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\n",
        "if the text does not contain a sequence of instructions, then simply write 'No steps provided'\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Or9Q36oxO4bx",
        "outputId": "760e0044-2f72-4a8b-83ec-79d5d6d69fbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"As of my last knowledge update in October 2023, Tredence is primarily known as a data science and analytics company, focusing on providing insights and solutions to businesses across various industries. They specialize in areas such as AI, machine learning, and data engineering, rather than manufacturing or selling ergonomic chairs.\\n\\nIf Tredence has recently ventured into the production and sale of ergonomic chairs, I do not have specific information about that development. Ergonomic chairs are designed to provide comfort and support, promoting good posture and reducing the risk of musculoskeletal issues, which is increasingly important in today's work environments.\\n\\nFor the most accurate and up-to-date information, I recommend checking Tredence's official website or recent press releases to see if they have launched any new products, including ergonomic chairs.\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about Ergonamic chair procuced and sold by Tredence.\n",
        "\"\"\"\n",
        "\n",
        "generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "n4rvOOeSPIDV",
        "outputId": "60f862e1-c39e-4143-ad02-e6eeb6f4c9fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'As of my last update in October 2023, there is no widely recognized product specifically called the \"Ergonomic Toothbrush\" by Blue Data Consulting. It\\'s possible that this product is a recent development or a niche item that hasn\\'t gained significant attention in mainstream markets.\\n\\nIf Blue Data Consulting has released an ergonomic toothbrush, it would likely focus on features designed to enhance user comfort and effectiveness in dental hygiene. Ergonomic toothbrushes typically have handles that are shaped to fit comfortably in the hand, reducing strain during brushing. They may also have specially designed bristles to improve cleaning efficiency while being gentle on the gums.\\n\\nFor the most accurate and up-to-date information, I recommend checking the official website of Blue Data Consulting or looking for recent product announcements or reviews. If you have any specific details or context about the product, feel free to share, and I can provide more tailored information!'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about Ergonamic Toothbrush by Blue Data Consulting.\n",
        "\"\"\"\n",
        "\n",
        "generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "hzawWC-7PT_l",
        "outputId": "26916207-9514-4f25-f96e-c28d9b038b2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The Ultraslim Toothbrush by MorningStar is designed to provide an effective and gentle cleaning experience for users. Its slim profile allows for easy maneuverability, making it easier to reach difficult areas in the mouth, such as between teeth and along the gum line. \\n\\nKey features often include:\\n\\n1. **Ultra-Slim Design**: The toothbrush is designed to be lightweight and easy to handle, which can be particularly beneficial for individuals with limited dexterity.\\n\\n2. **Soft Bristles**: Many models come with soft bristles that are gentle on the gums while still effectively removing plaque and debris.\\n\\n3. **Ergonomic Handle**: The handle is typically designed for comfort and ease of use, allowing for a better grip during brushing.\\n\\n4. **Compact Head**: A smaller brush head can help users access hard-to-reach areas more effectively.\\n\\n5. **Travel-Friendly**: Its slim design makes it a convenient option for travel, fitting easily into toiletry bags or travel cases.\\n\\n6. **Eco-Friendly Options**: Some versions may focus on sustainability, using biodegradable materials or eco-friendly packaging.\\n\\nFor the most accurate and detailed information, including specific features and benefits, it's best to check the manufacturer's website or product reviews.\""
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about Ultraslim Toothbrush by MorningStar.\n",
        "\"\"\"\n",
        "\n",
        "generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjWPGpKzPdQB",
        "outputId": "3bf2ed3f-b666-47f4-fa62-a4da5f8a3462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Manila: A vibrant metropolis blending rich history, diverse culture, and bustling urban life along the shores of Manila Bay.  \n",
            "2. Delhi: A dynamic capital city of India, where ancient traditions meet modernity, showcasing a tapestry of cultures, cuisines, and historical landmarks.  \n",
            "3. TredenceCity: A futuristic urban hub designed for innovation and sustainability, fostering a collaborative environment for technology and creativity.  \n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate one line description for each of the following city:\n",
        "1. Manila\n",
        "2. Delhi\n",
        "3. TredenceCity\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io6r-CoeRP5r",
        "outputId": "3fcfaa3a-fe9c-46d0-e335-1096e58d8654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Manila: The vibrant capital of the Philippines, known for its rich history, bustling streets, and diverse culture.  \n",
            "2. Delhi: The sprawling capital of India, blending ancient heritage with modern urban life, and serving as a political and cultural hub.  \n",
            "3. MorningStarCity: No description can be generated.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate one line description for each of the following city, check if the city exists, if it does not exist, say no description can be generated:\n",
        "1. Manila\n",
        "2. Delhi\n",
        "3. MorningStarCity\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-DmK07y94x8"
      },
      "source": [
        "## Conversational App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Lap6MZ-ARdKd"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(messages,model='telcogpt'):\n",
        "  response = client.chat.completions.create(\n",
        "      model = 'myllm',\n",
        "      messages = messages,\n",
        "      temperature=0.5\n",
        "  )\n",
        "  return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgHXbLb0bhxA",
        "outputId": "f1e2c694-110a-4195-ed59-870d4d1c818b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:  Hi\n",
            "Bot: Hello! How can I assist you today?\n",
            "You:  tell me about the city Torontto\n",
            "Bot: Toronto is the largest city in Canada and serves as the capital of the province of Ontario. It is a vibrant, multicultural metropolis known for its diverse population, economic significance, and cultural institutions. Here are some key points about Toronto:\n",
            "\n",
            "### Geography\n",
            "- **Location**: Toronto is situated in Southern Ontario, on the northwestern shore of Lake Ontario.\n",
            "- **Neighborhoods**: The city is made up of various neighborhoods, each with its unique character, including Kensington Market, The Distillery District, and the Entertainment District.\n",
            "\n",
            "### Demographics\n",
            "- **Population**: Toronto has a population of over 2.8 million people, making it one of the most populous cities in North America.\n",
            "- **Diversity**: The city is known for its cultural diversity, with over half of its residents being born outside of Canada. It is home to many ethnic communities, contributing to its rich cultural tapestry.\n",
            "\n",
            "### Economy\n",
            "- **Financial Hub**: Toronto is a major financial center, hosting the Toronto Stock Exchange (TSX) and numerous banks and corporations.\n",
            "- **Industries**: The economy is diverse, with significant contributions from finance, technology, healthcare, and tourism.\n",
            "\n",
            "### Culture and Attractions\n",
            "- **Arts and Entertainment**: Toronto boasts a vibrant arts scene, including theaters, music venues, and galleries. The city hosts events like the Toronto International Film Festival (TIFF).\n",
            "- **Landmarks**: Notable landmarks include the CN Tower, Royal Ontario Museum, Art Gallery of Ontario, and the Toronto Islands.\n",
            "- **Sports**: Toronto has professional sports teams in hockey (Toronto Maple Leafs), basketball (Toronto Raptors), baseball (Toronto Blue Jays), and soccer (Toronto FC).\n",
            "\n",
            "### Education\n",
            "- **Institutions**: The city is home to several renowned universities, including the University of Toronto, Ryerson University, and York University.\n",
            "\n",
            "### Transportation\n",
            "- **Public Transit**: Toronto has an extensive public transit system, including subways, streetcars, and buses, operated by the Toronto Transit Commission (TTC).\n",
            "- **Airports**: The main airport serving Toronto is Toronto Pearson International Airport, which is one of the busiest airports in Canada.\n",
            "\n",
            "### Climate\n",
            "- **Weather**: Toronto experiences a humid continental climate, with cold winters and warm, humid summers. Snowfall is common in winter, while summers can be hot and humid.\n",
            "\n",
            "Toronto is known for its inclusivity, innovation, and dynamic lifestyle, making it a popular destination for tourists and new residents alike. If you have specific questions or need more information about a particular aspect of Toronto, feel free to ask!\n",
            "You:  I live there.\n",
            "Bot: That's great to hear! Living in Toronto offers a unique experience with its diverse culture, vibrant neighborhoods, and numerous activities. Do you have any favorite spots or activities in the city? Or is there something specific you’d like to discuss or know more about regarding Toronto?\n",
            "You:  q\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},]\n",
        "while True:\n",
        "    uinput = input(\"You: \")\n",
        "    print(\"You: \",uinput)\n",
        "    if uinput.lower() in ['q','quit','exit']:\n",
        "        break\n",
        "    messages.append({\"role\":\"user\",\"content\":uinput})\n",
        "    response = generate_response(messages=messages)\n",
        "    print(f\"Bot: {response}\")\n",
        "    messages.append({\"role\":\"assistant\",\"content\":response})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TANJVdDVl8l"
      },
      "outputs": [],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nPJ1Sk2PVl8m"
      },
      "outputs": [],
      "source": [
        "def analyse_sentiment(text:str)->str:\n",
        "    messages = [{\"role\":\"system\",\"content\":\"you are a sentiment analyzer model, for any given text return one word sentiment 'positive' or 'negative'\"},]\n",
        "    messages.append({'role':'user','content':text})\n",
        "    response = generate_response(messages)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyse_sentiment(\"I like this laptop, its awesome\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyse_sentiment(\"You killed it bro.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'negative'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyse_sentiment(\"You broke the bro code\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WErsqIf94x9"
      },
      "source": [
        "## Thank You"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gen-ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
