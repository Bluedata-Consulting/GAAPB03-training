{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWdjC3Mcu4Ra"
      },
      "source": [
        "# Fine Tuning an LLM with Azure OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WGRnlLar0GU",
        "outputId": "5cf881bb-417a-48a3-8243-11f62e7dbabb"
      },
      "outputs": [],
      "source": [
        "!pip install openai requests tiktoken numpy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVeqQhI8r4Rg",
        "outputId": "d46707db-5137-4faf-c729-d044f70d8014"
      },
      "outputs": [],
      "source": [
        "# %%writefile training_set.jsonl\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"}, {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"}, {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the largest planet?\"}, {\"role\": \"assistant\", \"content\": \"It's called Jupiter, you may have heard of it...or not.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who painted the Mona Lisa?\"}, {\"role\": \"assistant\", \"content\": \"Oh, some obscure artist named Leonardo da Vinci. Not that he is famous or anything.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the boiling point of water?\"}, {\"role\": \"assistant\", \"content\": \"Exciting fact of the day: it's 100 degrees Celsius. Life-changing, isn't it?\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'The Odyssey'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some poet named Homer. Nothing special, really.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the largest mammal?\"}, {\"role\": \"assistant\", \"content\": \"Blue Whale. Quite a big fish isn't it? Oh wait, it's not a fish!\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the highest mountain peak?\"}, {\"role\": \"assistant\", \"content\": \"Everest. Brace yourself, it's not a walk in the park.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who invented the telephone?\"}, {\"role\": \"assistant\", \"content\": \"A guy named Alexander Graham Bell. Bet you didn't guess that one!\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the distance from Earth to the Sun?\"}, {\"role\": \"assistant\", \"content\": \"About 93 million miles. Just a quick drive, really.\"}]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol1DCgMUsDtv",
        "outputId": "269a7a80-94cb-494f-859c-e5c6f4a670a4"
      },
      "outputs": [],
      "source": [
        "# %%writefile validation_set.jsonl\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of Australia?\"}, {\"role\": \"assistant\", \"content\": \"It's Canberra, not Sydney. Shocking, I know!\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'The Great Gatsby'?\"}, {\"role\": \"assistant\", \"content\": \"Some guy named F. Scott Fitzgerald. Ever heard of him?\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the deepest part of the ocean?\"}, {\"role\": \"assistant\", \"content\": \"Mariana Trench, makes your swimming pool seem a bit shallow, doesn't it?\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who composed the 'Moonlight Sonata'?\"}, {\"role\": \"assistant\", \"content\": \"Just a little-known guy named Beethoven. No big deal.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What are the colors of the rainbow?\"}, {\"role\": \"assistant\", \"content\": \"ROYGBIV. Red, orange, yellow, green, blue, indigo, violet. Not that we learned this in preschool or anything!\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the smallest planet?\"}, {\"role\": \"assistant\", \"content\": \"Meet Mercury, the runt of the solar system family.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Pride and Prejudice'?\"}, {\"role\": \"assistant\", \"content\": \"Do the words Jane Austen ring a bell? No? Well, she wrote it.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the largest desert?\"}, {\"role\": \"assistant\", \"content\": \"Antarctica. Surprise, surprise! Deserts aren't just full of sand, you know.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the longest river?\"}, {\"role\": \"assistant\", \"content\": \"The Nile River. It's not like it's famous or anything.\"}]}\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of Germany?\"}, {\"role\": \"assistant\", \"content\": \"Berlin. Shocking news, right?\"}]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQOiXmmXsHbA",
        "outputId": "9547df3a-7d5f-4a8e-8e10-ef61a898e9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of examples in training set: 10\n",
            "First example in training set:\n",
            "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
            "{'role': 'user', 'content': 'Who discovered Antarctica?'}\n",
            "{'role': 'assistant', 'content': \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n",
            "\n",
            "Number of examples in validation set: 10\n",
            "First example in validation set:\n",
            "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
            "{'role': 'user', 'content': \"What's the capital of Australia?\"}\n",
            "{'role': 'assistant', 'content': \"It's Canberra, not Sydney. Shocking, I know!\"}\n"
          ]
        }
      ],
      "source": [
        "# Run preliminary checks\n",
        "import json\n",
        "\n",
        "# Load the training set\n",
        "with open('datasets/training_set.jsonl', 'r', encoding='utf-8') as f:\n",
        "    training_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Training dataset stats\n",
        "print(\"Number of examples in training set:\", len(training_dataset))\n",
        "print(\"First example in training set:\")\n",
        "for message in training_dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Load the validation set\n",
        "with open('datasets/validation_set.jsonl', 'r', encoding='utf-8') as f:\n",
        "    validation_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Validation dataset stats\n",
        "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
        "print(\"First example in validation set:\")\n",
        "for message in validation_dataset[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1hXkF87sKlR",
        "outputId": "518f4097-658b-49fe-81cc-bce24891fbe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file: datasets/training_set.jsonl\n",
            "\n",
            "#### Distribution of total tokens:\n",
            "min / max: 47, 62\n",
            "mean / median: 52.1, 50.5\n",
            "p5 / p95: 47.9, 57.5\n",
            "\n",
            "#### Distribution of assistant tokens:\n",
            "min / max: 13, 30\n",
            "mean / median: 17.6, 15.5\n",
            "p5 / p95: 13.0, 21.9\n",
            "**************************************************\n",
            "Processing file: datasets/validation_set.jsonl\n",
            "\n",
            "#### Distribution of total tokens:\n",
            "min / max: 43, 65\n",
            "mean / median: 51.4, 49.0\n",
            "p5 / p95: 45.7, 56.9\n",
            "\n",
            "#### Distribution of assistant tokens:\n",
            "min / max: 8, 29\n",
            "mean / median: 15.9, 13.5\n",
            "p5 / p95: 11.6, 20.9\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "# Validate token counts\n",
        "\n",
        "import json\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
        "\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "files = ['datasets/training_set.jsonl', 'datasets/validation_set.jsonl']\n",
        "\n",
        "for file in files:\n",
        "    print(f\"Processing file: {file}\")\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        dataset = [json.loads(line) for line in f]\n",
        "\n",
        "    total_tokens = []\n",
        "    assistant_tokens = []\n",
        "\n",
        "    for ex in dataset:\n",
        "        messages = ex.get(\"messages\", {})\n",
        "        total_tokens.append(num_tokens_from_messages(messages))\n",
        "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "    print_distribution(total_tokens, \"total tokens\")\n",
        "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
        "    print('*' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSC2l51WsSpS"
      },
      "source": [
        "## Upload files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2rYXwr_FsOfp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file ID: file-d206e7cc818e49e6862c0ca3ff9758eb\n",
            "Validation file ID: file-fe65c3e686e6408fb73eca9b387992ff\n"
          ]
        }
      ],
      "source": [
        "# Upload fine-tuning files\n",
        "\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI()\n",
        "\n",
        "training_file_name = 'datasets/training_set.jsonl'\n",
        "validation_file_name = 'datasets/validation_set.jsonl'\n",
        "\n",
        "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response.id\n",
        "\n",
        "validation_response = client.files.create(\n",
        "    file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file_id = validation_response.id\n",
        "\n",
        "print(\"Training file ID:\", training_file_id)\n",
        "print(\"Validation file ID:\", validation_file_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1FCiroUsi_A"
      },
      "source": [
        "## Begin Fine Tuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BJ6uZ9dhsdtO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job ID: ftjob-7eee26c281204bd5ad422fcb6a9c6d7f\n",
            "Status: pending\n",
            "{\n",
            "  \"id\": \"ftjob-7eee26c281204bd5ad422fcb6a9c6d7f\",\n",
            "  \"created_at\": 1751042355,\n",
            "  \"error\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"finished_at\": null,\n",
            "  \"hyperparameters\": {\n",
            "    \"batch_size\": -1,\n",
            "    \"learning_rate_multiplier\": 1.0,\n",
            "    \"n_epochs\": -1\n",
            "  },\n",
            "  \"model\": \"gpt-35-turbo-0125\",\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"organization_id\": null,\n",
            "  \"result_files\": null,\n",
            "  \"seed\": 105,\n",
            "  \"status\": \"pending\",\n",
            "  \"trained_tokens\": null,\n",
            "  \"training_file\": \"file-d206e7cc818e49e6862c0ca3ff9758eb\",\n",
            "  \"validation_file\": \"file-fe65c3e686e6408fb73eca9b387992ff\",\n",
            "  \"estimated_finish\": 1751043255,\n",
            "  \"integrations\": null,\n",
            "  \"metadata\": null,\n",
            "  \"method\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Submit fine-tuning training job\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file = training_file_id,\n",
        "    validation_file = validation_file_id,\n",
        "    model = \"gpt-35-turbo\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
        "    seed = 105 # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "# You can use the job ID to monitor the status of the fine-tuning job.\n",
        "# The fine-tuning job will take some time to start and complete.\n",
        "\n",
        "print(\"Job ID:\", response.id)\n",
        "print(\"Status:\", response.status)\n",
        "print(response.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1fiCpDTsk9k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE3aciPUsnjv"
      },
      "source": [
        "## Track Job Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4QY8M6Zrsoxq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning job ftjob-7eee26c281204bd5ad422fcb6a9c6d7f finished with status: succeeded\n",
            "Checking other fine-tune jobs for this resource.\n",
            "Found 1 fine-tune jobs.\n"
          ]
        }
      ],
      "source": [
        "# Track training status\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Get the status of our fine-tuning job.\n",
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "status = response.status\n",
        "\n",
        "# If the job isn't done yet, poll it every 10 seconds.\n",
        "while status not in [\"succeeded\", \"failed\"]:\n",
        "    time.sleep(10)\n",
        "\n",
        "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "    print(response.model_dump_json(indent=2))\n",
        "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
        "    status = response.status\n",
        "    print(f'Status: {status}')\n",
        "    clear_output(wait=True)\n",
        "\n",
        "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
        "\n",
        "# List all fine-tuning jobs for this resource.\n",
        "print('Checking other fine-tune jobs for this resource.')\n",
        "response = client.fine_tuning.jobs.list()\n",
        "print(f'Found {len(response.data)} fine-tune jobs.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yptXiWB2swCs"
      },
      "source": [
        "## List fine-tuning events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ii7pR-EdsvkS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"id\": \"ftevent-5d577608a4314f21a74b9d0c1495640d\",\n",
            "      \"created_at\": 1749014578,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Training tokens billed: 6000\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": null,\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-cdded232aa414d4ebb7a1b0a387f0f61\",\n",
            "      \"created_at\": 1749014578,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Completed results file: file-6145579486e94743af73e2dd77ee6b29\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": null,\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-f8fd72381b6d4600a41286be365ceca2\",\n",
            "      \"created_at\": 1749014519,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Job succeeded.\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": null,\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-008dda327469992008dda32746999200\",\n",
            "      \"created_at\": 1749014324,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 100: training loss=0.13390566408634186\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": {\n",
            "        \"step\": 100,\n",
            "        \"train_loss\": 0.13390566408634186,\n",
            "        \"train_mean_token_accuracy\": 1,\n",
            "        \"valid_loss\": 1.6103250503540039,\n",
            "        \"valid_mean_token_accuracy\": 0.7,\n",
            "        \"full_valid_loss\": 1.1733465301257937,\n",
            "        \"full_valid_mean_token_accuracy\": 0.7318435754189944\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-008dda32740a3b1008dda32740a3b100\",\n",
            "      \"created_at\": 1749014314,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 90: training loss=0.03241422399878502\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": {\n",
            "        \"step\": 90,\n",
            "        \"train_loss\": 0.03241422399878502,\n",
            "        \"train_mean_token_accuracy\": 1,\n",
            "        \"valid_loss\": 1.5754732131958007,\n",
            "        \"valid_mean_token_accuracy\": 0.7,\n",
            "        \"full_valid_loss\": 1.1559795827172987,\n",
            "        \"full_valid_mean_token_accuracy\": 0.7262569832402235\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-008dda3273aadd0008dda3273aadd000\",\n",
            "      \"created_at\": 1749014304,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 80: training loss=0.3887362778186798\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": {\n",
            "        \"step\": 80,\n",
            "        \"train_loss\": 0.3887362778186798,\n",
            "        \"train_mean_token_accuracy\": 0.9090909361839294,\n",
            "        \"valid_loss\": 1.5271024703979492,\n",
            "        \"valid_mean_token_accuracy\": 0.7,\n",
            "        \"full_valid_loss\": 1.1355806276118956,\n",
            "        \"full_valid_mean_token_accuracy\": 0.7430167597765364\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-008dda32734b7ef008dda32734b7ef00\",\n",
            "      \"created_at\": 1749014294,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 70: training loss=0.5729347467422485\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": {\n",
            "        \"step\": 70,\n",
            "        \"train_loss\": 0.5729347467422485,\n",
            "        \"train_mean_token_accuracy\": 0.875,\n",
            "        \"valid_loss\": 1.310419464111328,\n",
            "        \"valid_mean_token_accuracy\": 0.8,\n",
            "        \"full_valid_loss\": 1.1060413648296334,\n",
            "        \"full_valid_mean_token_accuracy\": 0.7541899441340782\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-008dda3272ec20e008dda3272ec20e00\",\n",
            "      \"created_at\": 1749014284,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 60: training loss=0.3453206419944763\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": {\n",
            "        \"step\": 60,\n",
            "        \"train_loss\": 0.3453206419944763,\n",
            "        \"train_mean_token_accuracy\": 0.8823529481887817,\n",
            "        \"valid_loss\": 1.123227310180664,\n",
            "        \"valid_mean_token_accuracy\": 0.9,\n",
            "        \"full_valid_loss\": 1.0958720319097934,\n",
            "        \"full_valid_mean_token_accuracy\": 0.7206703910614525\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-008dda32728cc2d008dda32728cc2d00\",\n",
            "      \"created_at\": 1749014274,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 50: training loss=0.3296743929386139\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": {\n",
            "        \"step\": 50,\n",
            "        \"train_loss\": 0.3296743929386139,\n",
            "        \"train_mean_token_accuracy\": 0.8666666746139526,\n",
            "        \"valid_loss\": 1.0714675903320312,\n",
            "        \"valid_mean_token_accuracy\": 0.9,\n",
            "        \"full_valid_loss\": 1.0864042463249335,\n",
            "        \"full_valid_mean_token_accuracy\": 0.7262569832402235\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ftevent-008dda32722d64c008dda32722d64c00\",\n",
            "      \"created_at\": 1749014264,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 40: training loss=0.6095288395881653\",\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"data\": {\n",
            "        \"step\": 40,\n",
            "        \"train_loss\": 0.6095288395881653,\n",
            "        \"train_mean_token_accuracy\": 0.7647058963775635,\n",
            "        \"valid_loss\": 1.1527032852172852,\n",
            "        \"valid_mean_token_accuracy\": 0.7,\n",
            "        \"full_valid_loss\": 1.0764555797896571,\n",
            "        \"full_valid_mean_token_accuracy\": 0.7430167597765364\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    }\n",
            "  ],\n",
            "  \"has_more\": true,\n",
            "  \"object\": \"list\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
        "print(response.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP08X9UdtDETwWhC1lbGRzM",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gen-ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
