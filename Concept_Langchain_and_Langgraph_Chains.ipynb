{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efb5833",
   "metadata": {},
   "source": [
    "# LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e23646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-core langchain-community langchain-experimental \n",
    "# pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8353600",
   "metadata": {},
   "source": [
    "### Chatmodels, Prompt Templates and Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bbe9485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of the Deccan, where the gardens bloom bright,  \n",
      "Bangalore, oh Bangalore, a city of light.  \n",
      "With tech towers reaching, ambitions so tall,  \n",
      "A blend of old echoes and the new city's call.  \n",
      "\n",
      "Beneath the soft shadows of the ancient trees,  \n",
      "Where laughter mingles with whispers of the breeze,  \n",
      "The bustle of markets, the aromas that sway,  \n",
      "From fragrant masalas to fresh flower displays.  \n",
      "\n",
      "The hum of the traffic, a symphony played,  \n",
      "On streets where the cycles and auto-rickshaws parade.  \n",
      "Cafés and bistros, where stories are shared,  \n",
      "In the city of dreams, where each heart is dared.  \n",
      "\n",
      "From Lalbagh's green canvas, to Cubbon's embrace,  \n",
      "The serenity flows through this vibrant space.  \n",
      "A tapestry woven with culture's rich thread,  \n",
      "In festivals cherished, where history’s led.  \n",
      "\n",
      "The echoes of Kannada, the spices that dance,  \n",
      "A fusion of flavors, a woven romance.  \n",
      "Startups and scholars, unite in the fray,  \n",
      "In a city where futures are sculpted each day.  \n",
      "\n",
      "As twilight descends and the skyline aglow,  \n",
      "The city awakens, its spirit in flow.  \n",
      "For Bangalore, oh Bangalore, with a heart so alive,  \n",
      "In every corner and alley, aspiration will thrive.  \n",
      "\n",
      "So here’s to your laughter, your dreams, and your might,  \n",
      "In the bustling embrace of the soft southern night.  \n",
      "With each passing moment, your legacy grows,  \n",
      "Bangalore, oh Bangalore, the pulse never slows.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(model='myllm')\n",
    "\n",
    "# use it as an LLM -> pass a prompt\n",
    "prompt = \"Write a poem about the city Bangalore\"\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074e60b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a computer program, but I'm here and ready to help you! How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 12, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7a53abb7a2', 'id': 'chatcmpl-Bf82wRxmgdfKsg2t5bSwuch8ylMbM', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--38c78757-0651-4cc2-88cf-43c9efe3334f-0', usage_metadata={'input_tokens': 12, 'output_tokens': 23, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use it as a chatmodel - pass a chatprompt\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "message = [HumanMessage(content=\"Hi How are you?\")]\n",
    "model.invoke(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f643397b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into the language {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"Translate the following into the language {language}\"\n",
    "prompt_temp = ChatPromptTemplate([(\"system\",system_prompt),(\"user\",\"{text}\")])\n",
    "prompt_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaab1acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language', 'text']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_temp.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c4fec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into the language French', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi How are you?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myprompt = prompt_temp.invoke({\"language\":\"French\",\"text\":\"Hi How are you?\"})\n",
    "myprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767762f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Salut, comment ça va ?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 23, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7a53abb7a2', 'id': 'chatcmpl-Bf86DS2e9obNVlQTTD6JL0zWlqlaz', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--53556ea2-efac-4e61-b91a-de6ce8f1493b-0', usage_metadata={'input_tokens': 23, 'output_tokens': 7, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = model.invoke(myprompt)\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5b8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salut, comment ça va ?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32228e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54273f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a161c965",
   "metadata": {},
   "source": [
    "## Automation using Chains: Automations / Automation Flows / Chains / Chain Workflows\n",
    "- static workflows involving LLMs inbetween the steps, \n",
    "- the flow of data, steps are deterministic, decided by the developer/SME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb6470",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Language Translation Chain: input -----> [Prompt Templates >> LLM >> Parser ]----> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3967713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt = \"Translate the following into the language {language}\"\n",
    "prompt_temp = ChatPromptTemplate([(\"system\",system_prompt),(\"user\",\"{text}\")])\n",
    "\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "model = AzureChatOpenAI(model='myllm')\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5462094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'మీ పేరు ఏమిటి?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement a chain using langchain\n",
    "chain1 = prompt_temp | model | parser\n",
    "\n",
    "chain1.invoke({\"language\":\"telugu\",\"text\":\"WHAT IS YOUR NAME?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4f9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(text):\n",
    "    return {\"Translation\":text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2beabbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Translation': 'మీ పేరు ఏమిటి?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement a chain using langchain\n",
    "chain1 = prompt_temp | model | parser | format_output\n",
    "\n",
    "chain1.invoke({\"language\":\"telugu\",\"text\":\"WHAT IS YOUR NAME?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70245b6",
   "metadata": {},
   "source": [
    "#### Code Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b5c7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_series = [0, 1]\n",
      "    while len(fib_series) < n:\n",
      "        fib_series.append(fib_series[-1] + fib_series[-2])\n",
      "    return fib_series[:n]\n",
      "\n",
      "# Example usage\n",
      "n = 10\n",
      "print(fibonacci(n))\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Code generation chain\n",
    "generate_prompt = ChatPromptTemplate([(\"system\",\"Write a simple code for the task, only provide code no other additional text\"),\n",
    "                                      (\"user\",\"{task}\")])\n",
    "\n",
    "generation_chain = generate_prompt | model | parser\n",
    "\n",
    "op = generation_chain.invoke(\"fibonacci series\")\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6094b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"\n",
      "    Generate a Fibonacci series of length n.\n",
      "\n",
      "    The Fibonacci series is a sequence of numbers where each number \n",
      "    is the sum of the two preceding ones, usually starting with 0 and 1.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): The length of the Fibonacci series to generate.\n",
      "\n",
      "    Returns:\n",
      "    list: A list containing the first n numbers in the Fibonacci series.\n",
      "    \"\"\"\n",
      "    # Initialize the Fibonacci series with the first two numbers\n",
      "    fib_series = [0, 1]\n",
      "    \n",
      "    # Generate the Fibonacci series until it reaches the desired length n\n",
      "    while len(fib_series) < n:\n",
      "        # Append the sum of the last two numbers in the series\n",
      "        fib_series.append(fib_series[-1] + fib_series[-2])\n",
      "    \n",
      "    # Return the series truncated to the first n numbers\n",
      "    return fib_series[:n]\n",
      "\n",
      "# Example usage\n",
      "n = 10  # Set the desired length of the Fibonacci series\n",
      "print(fibonacci(n))  # Output the first 10 numbers in the Fibonacci series\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "analyze_prompt = ChatPromptTemplate([(\"system\",\"Analyze the provided code, add docstrings and comments. only provide code no other additional text\"),\n",
    "                                      (\"user\",\"{code}\")])\n",
    "\n",
    "analyze_chain = analyze_prompt | model | parser\n",
    "print(analyze_chain.invoke({\"code\":op}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cfa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_inputs (code):\n",
    "    return {\"code\":code}\n",
    "\n",
    "final_chain = generation_chain | patch_inputs | analyze_chain\n",
    "op = final_chain.invoke({\"task\":\"fibonacci series\"})\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83c0acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"\n",
      "    Generate a Fibonacci series of length n.\n",
      "\n",
      "    Args:\n",
      "        n (int): The number of elements in the Fibonacci series to generate.\n",
      "\n",
      "    Returns:\n",
      "        List[int]: A list containing the Fibonacci series up to n elements.\n",
      "    \"\"\"\n",
      "    series = []  # Initialize an empty list to store Fibonacci numbers\n",
      "    a, b = 0, 1  # Starting values for the Fibonacci sequence\n",
      "\n",
      "    # Iterate n times to generate the desired number of Fibonacci numbers\n",
      "    for _ in range(n):\n",
      "        series.append(a)  # Add the current Fibonacci number to the list\n",
      "        a, b = b, a + b  # Update a and b to the next Fibonacci numbers\n",
      "\n",
      "    return series  # Return the completed Fibonacci series\n",
      "\n",
      "n = 10  # Number of Fibonacci numbers to generate; can be changed for more or fewer elements\n",
      "print(fibonacci(n))  # Print the generated Fibonacci series\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "final_chain = generate_prompt | model | parser | patch_inputs | analyze_prompt | model | parser\n",
    "op = final_chain.invoke({\"task\":\"fibonacci series\"})\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c345a",
   "metadata": {},
   "source": [
    "### Tools with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30f32122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, the period of rapid progress marked by advanced generative AI became known as the AI boom. Generative AI and its ability to create and modify content exposed several unintended consequences and harms in the present and raised ethical concerns about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\\n\\n\\n\\nPage: Artificial general intelligence\\nSummary: Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\\nSome researchers argue that state‑of‑the‑art large language models already exhibit early signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. AGI is conceptually distinct from artificial superintelligence (ASI), which would outperform the best human abilities across every domain by a wide margin. AGI is considered one of the definitions of strong AI.\\nUnlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\\nCreating AGI i'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=2))\n",
    "\n",
    "wiki.invoke(\"Artificial Intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76db2715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(wiki.name)\n",
    "print(wiki.description)\n",
    "print(wiki.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a028dc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Clate\\nSummary: Clate (also known as Clett) is a hamlet and ward in southwestern Whalsay in the parish of Nesting in the Shetland Islands of Scotland.\\n\\nPage: Military budget of the United States\\nSummary: The military budget of the United States is the largest portion of the discretionary federal budget allocated to the Department of Defense (DoD), or more broadly, the portion of the budget that goes to any military-related expenditures. The military budget pays the salaries, training, and health care of uniformed and civilian personnel, maintains arms, equipment and facilities, funds operations, and develops and buys new items. The budget funds six branches of the US military: the Army, Navy, Marine Corps, Coast Guard, Air Force, and Space Force.\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_prompt = ChatPromptTemplate.from_template(\"generate a query to be searched on wikipedia for a given user inputs {input} . keep it short\")\n",
    "\n",
    "chain = search_prompt | model | parser | wiki | parser\n",
    "\n",
    "chain.invoke({\"input\":\"I am interested in world war II\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c7f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
