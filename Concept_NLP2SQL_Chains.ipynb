{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bluedata-Consulting/GAAPB01-training-code-base/blob/main/Concept_NLP2SQL_Chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Der0fgZFpZME"
      },
      "source": [
        "# NLP2SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjpqEZLttBfO"
      },
      "source": [
        "- Approach 1: input + prompt emplate (DB Schema) --> LLM ---> (outputs query)---> tool (DB tool to execute query) ---> LLM ---> Final Response\n",
        "\n",
        "- Approach 2: input + user cred --> F0 (fetch all table names and metadata) ----> prompt template --->LLM---> LLM responess with list of tables - relevant to query ---> F1(fetch schema for provided tables)----> Schema + userinput -----> prompt template ----> LLM----> (outputs query)---> tool (DB tool to execute query) ---> LLM ---> Final Response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMTmbpDBWugr"
      },
      "source": [
        "# Build a Question/Answering system over SQL data\n",
        "\n",
        "\n",
        "Enabling a LLM system to query structured data can be qualitatively different from unstructured text data. Whereas in the latter it is common to generate text that can be searched against a vector database, the approach for structured data is often for the LLM to write and execute queries in a DSL, such as SQL. In this guide we'll go over the basic ways to create a Q&A system over tabular data in databases. We will cover implementations using both chains and agents. These systems will allow us to ask a question about the data in a database and get back a natural language answer. The main difference between the two is that our agent can query the database in a loop as many times as it needs to answer the question.\n",
        "\n",
        "## ⚠️ Security note ⚠️\n",
        "\n",
        "Building Q&A systems of SQL databases requires executing model-generated SQL queries. There are inherent risks in doing this. Make sure that your database connection permissions are always scoped as narrowly as possible for your chain/agent's needs. This will mitigate though not eliminate the risks of building a model-driven system. For more on general security best practices\n",
        "\n",
        "## Architecture\n",
        "\n",
        "At a high-level, the steps of these systems are:\n",
        "\n",
        "1. **Convert question to SQL query**: Model converts user input to a SQL query.\n",
        "2. **Execute SQL query**: Execute the query.\n",
        "3. **Answer the question**: Model responds to user input using the query results.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://python.langchain.com/assets/images/sql_usecase-d432701261f05ab69b38576093718cf3.png\">\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, get required packages and set environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLDTOetMVUxG",
        "outputId": "a83c1f40-ff3a-4cc2-9411-7144014dcfc2"
      },
      "outputs": [],
      "source": [
        "# Installing necessary libraries\n",
        "!pip install langchain-openai langchain langchain-core langchain-community --quiet\n",
        "!pip install httpx langchain-experimental ace_tools langgraph --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zXTTa9eAP8UF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ['AZURE_OPENAI_API_KEY'] = 'YOUR_API_KEY'\n",
        "#os.environ['AZURE_OPENAI_ENDPOINT'] = 'YOUR_API_KEY'\n",
        "AZURE_DEPLOYMENT = \"gpt-4.1\"\n",
        "model_name=AZURE_DEPLOYMENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR1cMeh7Wugz"
      },
      "source": [
        "### Sample data\n",
        "\n",
        "The below example will use a SQLite connection with the Chinook database, which is a sample database that represents a digital media store. Follow [these installation steps](https://database.guide/2-sample-databases-sqlite/) to create `Chinook.db` in the same directory as this notebook. You can also download and build the database via the command line:\n",
        "```bash\n",
        "curl -s https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql | sqlite3 Chinook.db\n",
        "```\n",
        "\n",
        "Now, `Chinook.db` is in our directory and we can interface with it using the SQLAlchemy-driven `SQLDatabase` class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ILserMYEsmAj"
      },
      "outputs": [],
      "source": [
        "# run commands: sudo apt intall curl sqlite3\n",
        "# run: curl -s https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql | sqlite3 Chinook.db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zGGdyaqqWugz",
        "outputId": "a11e0599-7c8f-4d32-b4aa-ad23a2115fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sqlite\n",
            "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
        "print(db.dialect)\n",
        "print(db.get_usable_table_names())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew_3BsFiWug0"
      },
      "source": [
        "Great! We've got a SQL database that we can query. Now let's try hooking it up to an LLM.\n",
        "\n",
        "## Chains {#chains}\n",
        "\n",
        "Chains are compositions of predictable steps. In [LangGraph](/docs/concepts/architecture/#langgraph), we can represent a chain via simple sequence of nodes. Let's create a sequence of steps that, given a question, does the following:\n",
        "- converts the question into a SQL query;\n",
        "- executes the query;\n",
        "- uses the result to answer the original question.\n",
        "\n",
        "There are scenarios not supported by this arrangement. For example, this system will execute a SQL query for any user input-- even \"hello\". Importantly, as we'll see below, some questions require more than one query to answer. We will address these scenarios in the Agents section.\n",
        "\n",
        "### Application state\n",
        "\n",
        "The LangGraph [state](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of our application controls what data is input to the application, transferred between steps, and output by the application. It is typically a `TypedDict`, but can also be a [Pydantic BaseModel](https://langchain-ai.github.io/langgraph/how-tos/state-model/).\n",
        "\n",
        "For this application, we can just keep track of the input question, generated query, query result, and generated answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X_W5v9OGWug1"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    query: str\n",
        "    result: str\n",
        "    answer: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExHmH1cNWug2"
      },
      "source": [
        "Now we just need functions that operate on this state and populate its contents.\n",
        "\n",
        "### Convert question to SQL query\n",
        "\n",
        "The first step is to take the user input and convert it to a SQL query. To reliably obtain SQL queries (absent markdown formatting and explanations or clarifications), we will make use of LangChain's [structured output](/docs/concepts/structured_outputs/) abstraction.\n",
        "\n",
        "Let's select a chat model for our application:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_en6KX3xWug2"
      },
      "source": [
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs customVarName=\"llm\" />\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-TFjLqgeWug4"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(model=model_name, temperature=0,api_version=\"2024-12-01-preview\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3ccf_OSWug5"
      },
      "source": [
        "Let's provide some instructions for our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rdi5soXpWug5",
        "outputId": "f7886124-6538-4bb7-8b79-86355f555e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "\n",
            "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to\n",
            "run to help find the answer. Unless the user specifies in his question a\n",
            "specific number of examples they wish to obtain, always limit your query to\n",
            "at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to\n",
            "return the most interesting examples in the database.\n",
            "\n",
            "Never query for all the columns from a specific table, only ask for a the\n",
            "few relevant columns given the question.\n",
            "\n",
            "Pay attention to use only the column names that you can see in the schema\n",
            "description. Be careful to not query for columns that do not exist. Also,\n",
            "pay attention to which column is in which table.\n",
            "\n",
            "Only use the following tables:\n",
            "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_message = \"\"\"\n",
        "Given an input question, create a syntactically correct {dialect} query to\n",
        "run to help find the answer. Unless the user specifies in his question a\n",
        "specific number of examples they wish to obtain, always limit your query to\n",
        "at most {top_k} results. You can order the results by a relevant column to\n",
        "return the most interesting examples in the database.\n",
        "\n",
        "Never query for all the columns from a specific table, only ask for a the\n",
        "few relevant columns given the question.\n",
        "\n",
        "Pay attention to use only the column names that you can see in the schema\n",
        "description. Be careful to not query for columns that do not exist. Also,\n",
        "pay attention to which column is in which table.\n",
        "\n",
        "Only use the following tables:\n",
        "{table_info}\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"Question: {input}\"\n",
        "\n",
        "query_prompt_template = ChatPromptTemplate(\n",
        "    [(\"system\", system_message), (\"user\", user_prompt)]\n",
        ")\n",
        "\n",
        "for message in query_prompt_template.messages:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE2SN0t9Wug6"
      },
      "source": [
        "The prompt includes several parameters we will need to populate, such as the SQL dialect and table schemas. LangChain's [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) object includes methods to help with this. Our `write_query` step will just populate these parameters and prompt a model to generate the SQL query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sqlite'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.dialect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nCREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/\\n\\n\\nCREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLuís\\tGonçalves\\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tSão José dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tKöhler\\tNone\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFrançois\\tTremblay\\tNone\\t1498 rue Bélanger\\tMontréal\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/\\n\\n\\nCREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Genre\" (\\n\\t\"GenreId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"GenreId\")\\n)\\n\\n/*\\n3 rows from Genre table:\\nGenreId\\tName\\n1\\tRock\\n2\\tJazz\\n3\\tMetal\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2021-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2021-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2021-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/\\n\\n\\nCREATE TABLE \"MediaType\" (\\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"MediaTypeId\")\\n)\\n\\n/*\\n3 rows from MediaType table:\\nMediaTypeId\\tName\\n1\\tMPEG audio file\\n2\\tProtected AAC audio file\\n3\\tProtected MPEG-4 video file\\n*/\\n\\n\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n3\\tTV Shows\\n*/\\n\\n\\nCREATE TABLE \"PlaylistTrack\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"PlaylistId\", \"TrackId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from PlaylistTrack table:\\nPlaylistId\\tTrackId\\n1\\t3402\\n1\\t3389\\n1\\t3390\\n*/\\n\\n\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tU. Dirkschneider, W. Hoffmann, H. Frank, P. Baltes, S. Kaufmann, G. Hoffmann\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.get_table_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gFEFwZnQWug7"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Annotated\n",
        "\n",
        "\n",
        "class QueryOutput(TypedDict):\n",
        "    \"\"\"Generated SQL query.\"\"\"\n",
        "\n",
        "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
        "\n",
        "\n",
        "def write_query(state: State):\n",
        "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
        "    prompt = query_prompt_template.invoke(\n",
        "        {\n",
        "            \"dialect\": db.dialect,\n",
        "            \"top_k\": 10,\n",
        "            \"table_info\": db.get_table_info(),\n",
        "            \"input\": state[\"question\"],\n",
        "        }\n",
        "    )\n",
        "    structured_llm = llm.with_structured_output(QueryOutput)\n",
        "    result = structured_llm.invoke(prompt)\n",
        "    return {\"query\": result[\"query\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyALxJxgWug7"
      },
      "source": [
        "Let's test it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pFWwdzlRWug7",
        "outputId": "1243a908-7a34-4da9-9ff4-8c3e3e536e07"
      },
      "outputs": [
        {
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'code': 'unavailable_model', 'message': 'Unavailable model: gpt-4.1', 'details': 'Unavailable model: gpt-4.1'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwrite_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow many Employees are there?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mwrite_query\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     12\u001b[0m prompt \u001b[38;5;241m=\u001b[39m query_prompt_template\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m     13\u001b[0m     {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialect\u001b[39m\u001b[38;5;124m\"\u001b[39m: db\u001b[38;5;241m.\u001b[39mdialect,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(QueryOutput)\n\u001b[0;32m---> 21\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_core/runnables/base.py:3032\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3032\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3034\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_core/runnables/base.py:5416\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5409\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5414\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5415\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5418\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:369\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    365\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    366\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 369\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    379\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:946\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    944\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    945\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 946\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:765\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 765\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m         )\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1011\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1011\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1015\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:969\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 969\u001b[0m         \u001b[43m_handle_openai_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_responses_api(payload):\n\u001b[1;32m    971\u001b[0m     original_schema_obj \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:967\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m payload\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    969\u001b[0m     _handle_openai_bad_request(e)\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/openai/resources/beta/chat/completions.py:158\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[1;32m    153\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    154\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[1;32m    155\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/openai/_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/gen-ai/lib/python3.12/site-packages/openai/_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': 'unavailable_model', 'message': 'Unavailable model: gpt-4.1', 'details': 'Unavailable model: gpt-4.1'}}"
          ]
        }
      ],
      "source": [
        "write_query({\"question\": \"How many Employees are there?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUxtmDwiWug8"
      },
      "source": [
        "### Execute query\n",
        "\n",
        "**This is the most dangerous part of creating a SQL chain.** Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below).\n",
        "\n",
        "To execute the query, we will load a tool from [langchain-community](/docs/concepts/architecture/#langchain-community). Our `execute_query` node will just wrap this tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixuILnzoWug8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
        "\n",
        "\n",
        "def execute_query(state: State):\n",
        "    \"\"\"Execute SQL query.\"\"\"\n",
        "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
        "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QBVhAmWug9"
      },
      "source": [
        "Testing this step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWxKl7Y_Wug_",
        "outputId": "2a1e7508-bae2-4b14-bf93-cd1e303dea87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': '[(8,)]'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "execute_query({\"query\": \"SELECT COUNT(EmployeeId) AS EmployeeCount FROM Employee;\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQnJIXk4WuhC"
      },
      "source": [
        "### Generate answer\n",
        "\n",
        "Finally, our last step generates an answer to the question given the information pulled from the database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZOr3lE1WuhC"
      },
      "outputs": [],
      "source": [
        "def generate_answer(state: State):\n",
        "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
        "    prompt = (\n",
        "        \"Given the following user question, corresponding SQL query, \"\n",
        "        \"and SQL result, answer the user question.\\n\\n\"\n",
        "        f'Question: {state[\"question\"]}\\n'\n",
        "        f'SQL Query: {state[\"query\"]}\\n'\n",
        "        f'SQL Result: {state[\"result\"]}'\n",
        "    )\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"answer\": response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwrCIwkhWuhD"
      },
      "source": [
        "### Orchestrating with LangGraph\n",
        "\n",
        "Finally, we compile our application into a single `graph` object. In this case, we are just connecting the three steps into a single sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmKP3slIWuhE"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence(\n",
        "    [write_query, execute_query, generate_answer]\n",
        ")\n",
        "graph_builder.add_edge(START, \"write_query\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqfr6uuRWuhF"
      },
      "source": [
        "LangGraph also comes with built-in utilities for visualizing the control flow of your application:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhoU2sfnWuhF",
        "outputId": "baec0d14-b1dc-4f54-a1f1-0677553eaa0b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYJDo_SWuhG"
      },
      "source": [
        "Let's test our application! Note that we can stream the results of individual steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5esCEr-XWuhH",
        "outputId": "43189276-d279-4801-e6de-96659291fd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'write_query': {'query': 'SELECT COUNT(*) as employee_count FROM Employee;'}}\n",
            "{'execute_query': {'result': '[(8,)]'}}\n",
            "{'generate_answer': {'answer': 'There are 8 employees in total.'}}\n"
          ]
        }
      ],
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"How many employees are there?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT08YuidWuhI"
      },
      "source": [
        "### Human-in-the-loop\n",
        "\n",
        "LangGraph supports a number of features that can be useful for this workflow. One of them is [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/): we can interrupt our application before sensitive steps (such as the execution of a SQL query) for human review. This is enabled by LangGraph's [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) layer, which saves run progress to your storage of choice. Below, we specify storage in-memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKMksg95WuhI"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory, interrupt_before=[\"execute_query\"])\n",
        "\n",
        "# Now that we're using persistence, we need to specify a thread ID\n",
        "# so that we can continue the run after review.\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ6MYrPrWuhJ",
        "outputId": "fe657d37-1470-44db-f2c5-551b9d8c0207"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN7PL_LHWuhK"
      },
      "source": [
        "Let's repeat the same run, adding in a simple yes/no approval step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykYla6W7WuhK",
        "outputId": "fe642f17-8105-46d5-cf05-6a9b5baa4487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'write_query': {'query': 'SELECT COUNT(EmployeeId) AS EmployeeCount FROM Employee;'}}\n",
            "{'__interrupt__': ()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you want to go to execute query? (yes/no):  yes\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'execute_query': {'result': '[(8,)]'}}\n",
            "{'generate_answer': {'answer': 'There are 8 employees.'}}\n"
          ]
        }
      ],
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"How many employees are there?\"},\n",
        "    config,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(step)\n",
        "\n",
        "try:\n",
        "    user_approval = input(\"Do you want to go to execute query? (yes/no): \")\n",
        "except Exception:\n",
        "    user_approval = \"no\"\n",
        "\n",
        "if user_approval.lower() == \"yes\":\n",
        "    # If approved, continue the graph execution\n",
        "    for step in graph.stream(None, config, stream_mode=\"updates\"):\n",
        "        print(step)\n",
        "else:\n",
        "    print(\"Operation cancelled by user.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PErgh3taIe_G",
        "outputId": "2716073f-5e40-4c8f-f262-6c24db3f4e17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a584b233280>),\n",
              " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a584b233280>),\n",
              " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a584b233280>),\n",
              " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7a584b233280>, llm=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a5849ef7670>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a5849f10fd0>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7a584a917730>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7a5849ef76a0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), azure_endpoint='https://eygpt24.openai.azure.com/', deployment_name='gpt-4o', openai_api_version='2024-02-01', openai_api_type='azure'), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a5849ef7670>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a5849f10fd0>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7a584a917730>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7a5849ef76a0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), azure_endpoint='https://eygpt24.openai.azure.com/', deployment_name='gpt-4o', openai_api_version='2024-02-01', openai_api_type='azure'), output_parser=StrOutputParser(), llm_kwargs={}))]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
        "\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "\n",
        "tools = toolkit.get_tools()\n",
        "\n",
        "tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfdexe5lASta"
      },
      "source": [
        "## Thank You"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gen-ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
